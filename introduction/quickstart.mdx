---
title: "Quickstart"
---

Here is a quick walkthrough to get you started with Inferless to deploy your first machine learning model. 

Language Supported: **Python** 

### Step 1: Clone the Template Repository to your Github 

We have created a Template repository that you can use as a base to inject your code you can find a sample here with the GPT Neo model. 

Github Repo: [https://github.com/infer-less/template-method](https://github.com/infer-less/template-method)

```python
## Implement the Load function here for the model 
    def initialize(self):
        self.generator = pipeline("text-generation", model="EleutherAI/gpt-neo-125M",device=0)
    
# Function to perform inference 
    def infer(self, inputs):
        # inputs is a dictionary where the keys are input names and values are actual input data
        # e.g. in the below code the input name is "prompt"
        prompt = inputs["prompt"]
        pipeline_output = self.generator(prompt, do_sample=True, min_length=20)
        generated_txt = pipeline_output[0]["generated_text"]
        # The output generated by the infer function should be a dictionary where keys are output names and values are actual output data
        # e.g. in the below code the output name is "generated_txt"
        return {"generated_text": generated_txt}

# perform any cleanup activity here
    def finalize(self,args):
        self.pipe = None
```

input\_schema.py 

```input_schema
INPUT_SCHEMA = {
    "prompt": {
        'datatype': 'STRING',
        'required': True,
        'shape': [1],
        'example': ["There is a fine house in the forest"]
    }
}
```

### Step 2: Login to the inferless dashboard can click on Import model button 

* Navigate to your desired workspace in Inferless and Click on `"Add a Custom Model" `button that you see on the top right 

<Frame caption = "Click on Add Custom Model">![](/images/quickstart-1.png)</Frame>

### Step 3: Follow steps to complete the model import

- Select the Githib/Gitlab Integration 
- Select the Github Repo that has the model code and enter the model name
- Choose the type of machine, and specify the minimum and maximum number of replicas for deploying your model
- Optionally you can configure Automatic build and deploy on code push
- Configure Custom Runtime (If you have pip or apt packages) and Environment variables like Inference Timeout / Container Concurrency / Scale Down Timeout
- Let the Validation Complete and click on Import button

<Frame caption = "Model Details">![](/images/quickstart-2.png)</Frame>

### Step 4: Wait for the model build to complete usually takes ~5-10 minutes 

You can see the progress of the model build on the progress page

<Frame caption = "Progress Page">![](/images/quickstart-3.png)</Frame>

### Step 5: Use the APIs to call the model 

Once the model is in 'Active' status you can click on the 'API' page to try the model with sample inputs.

<Frame caption = "Model Details">![](/images/quickstart-4.png)</Frame>














