---
title: "Quickstart"
---

Here is a quick walkthrough to get you started with Inferless to deploy your first machine learning model. 

Language Supported: **Python** 

### Step 1: Clone the Template Repository to your Github 

We have created a Template repository that you can use as a base to inject your code you can find a sample here with the GPT Neo model. 

Github Repo: [https://github.com/infer-less/template-method](https://github.com/infer-less/template-method)

```python
## Implement the Load function here for the model 
    def initialize(self):
        self.generator = pipeline("text-generation", model="EleutherAI/gpt-neo-125M",device=0)
    
# Function to perform inference 
    def infer(self, inputs):
        # inputs is a dictionary where the keys are input names and values are actual input data
        # e.g. in the below code the input name is "prompt"
        prompt = inputs["prompt"]
        pipeline_output = self.generator(prompt, do_sample=True, min_length=20)
        generated_txt = pipeline_output[0]["generated_text"]
        # The output generated by the infer function should be a dictionary where keys are output names and values are actual output data
        # e.g. in the below code the output name is "generated_txt"
        return {"generated_text": generated_txt}

# perform any cleanup activity here
    def finalize(self,args):
        self.pipe = None
```

input\_schema.py 

```input_schema
INPUT_SCHEMA = {
    "prompt": {
        'datatype': 'STRING',
        'required': True,
        'shape': [1],
        'example': ["There is a fine house in the forest"]
    }
}
```

### Step 2: Login to the inferless dashboard can click on Import model button 

* Navigate to your desired workspace in Inferless and Click on `"Add a custom model" `button that you see on the top right. An import wizard will open up.

<Frame caption = "Click on Add Model">![](/images/github-demo1.png)</Frame>


### Step 3: Follow the Wizard to enter model detials 

- Select the libray(Pytorch/Tensorflow/Onnx) used to be used for inference(Step 1)
- Select the Github option and click on `Connect with Github` button  (Step 2) 
- Authorize Inferless to access your Github account  (Step 2)
- Select the Github Repo that has the model code and enter the model name (Step 3)
- Choose the type of machine, and specify the minimum and maximum number of replicas for deploying your model (Step 4).
- Optionally you can configure Automatic build, Custom Runtime, Environment variables (Step 4)
- Review and click on `Submit` button (Step 5)


### Step 4: Wait for the model build to complete usually takes ~5-10 minutes 

You can see the progress of the model build in the 

<Frame caption = "Click on Add Model">![](/images/github-demo1.png)</Frame>

### Step 5: Use the APIs to call the model 

Once the model is in 'Active' status you can click on the 'API' page to call the model

<Frame caption = "Click on Add Model">![](/images/github-demo1.png)</Frame>














